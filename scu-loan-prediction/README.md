# ðŸ¦ Loan Grade & Diabetes Classification (SCU AI Competition â€“ Excellence Award)

This project was developed for the 2nd AI Competition hosted by Seoul Cyber University.  
The goal was to predict:
- **Loan Grade (multi-class classification)**
- **Diabetes Status (binary classification)**

---

## ðŸ† Award
- **Excellence Award (ìš°ìˆ˜ìƒ)**  
  Awarded based on combined performance in two tasks:

### ðŸ¥‡ Task 1: Loan Grade Prediction (Multi-class Classification)
- [Leaderboard Link](https://www.kaggle.com/competitions/2-ai-loan/leaderboard)

### ðŸ¥ˆ Task 2: Diabetes Prediction (Binary Classification)
- [Leaderboard Link](https://www.kaggle.com/competitions/2-ai/leaderboard)

> ðŸ§® Final score was based on the average performance across both tasks.

---

## ðŸ” Problem Overview

Two tasks were involved:
1. **Loan grade prediction** using customer financial data
2. **Diabetes classification** using medical information

The main challenge was designing effective preprocessing and feature engineering strategies  
to improve model performance on tabular data.

---

## ðŸ“¦ Baseline Code Overview

The competition provided a basic starter notebook as a baseline.  
It used minimal preprocessing and applied a `RandomForestClassifier` to the loan grade prediction task.

### ðŸ“„ What the baseline did:
- Dropped ID and label columns
- Applied simple `train_test_split` (no cross-validation)
- No missing value treatment
- No feature engineering
- No model tuning
- Used only `RandomForestClassifier`

This baseline achieved a reasonable initial score but left much room for improvement.

### ðŸš© My Takeaways
- The baseline was helpful for understanding the structure of the data
- But the lack of preprocessing and feature engineering limited its performance
- It served as a foundation for iterative experimentation and model improvement
ðŸ“„ [Baseline Notebook: ê³ ê°ëŒ€ì¶œë“±ê¸‰ ì™„ì „ ë² ì´ìŠ¤.ipynb](./ê³ ê°ëŒ€ì¶œë“±ê¸‰ ì™„ì „ ë² ì´ìŠ¤.ipynb)

---

---

## ðŸ§ª Experiment Timeline Summary

Over 40+ submissions, I iteratively refined the model through:

### ðŸ”¹ Phase 1: Establishing a Baseline (Submissions #1â€“#3)
- Minimal preprocessing
- Early imputation methods (mean, median)
- Initial feature engineering attempts
- ðŸ“ˆ Small score improvements

---

### ðŸ”¹ Phase 2: Feature Engineering & Selection (Submissions #4â€“#12)
- Created domain-specific features:
  - ì´ìžë¶€ë‹´ìœ¨ (interest burden ratio)
  - ê·¼ë¡œê¸°ê°„ ëŒ€ë¹„ ì‹ ìš©ê±°ëž˜ê¸°ê°„ ë¹„ìœ¨
- Tried scaling & encoding strategies
- ðŸ”¥ Best single-feature performance from ì´ìžë¶€ë‹´ìœ¨ alone (`0.6935`)

---

### ðŸ”¹ Phase 3: Model Exploration & Tuning (Submissions #6â€“#13)
- Compared LightGBM, CatBoost, RandomForest, SVM
- Rejected underperformers (e.g., RandomForest)
- Tuned LightGBM & applied ensemble
- âœ… Best score achieved with **LightGBM + Ensemble** in submission #13

---

### ðŸ”¹ Phase 4: Advanced Feature Selection (Submissions #21â€“#30)
- Feature importance-based selection
- Voting/stacking ensemble with top N features
- Applied regularization to reduce overfitting

---

### ðŸ”¹ Phase 5: Post-peak Optimization (Submissions #31â€“#47)
- Experiments with feature reordering, interaction variables
- Explored Optuna tuning & model combinations
- Some regressions observed, validating importance of simplicity

---

ðŸ“Œ Throughout the process, I emphasized reproducibility, hypothesis-driven testing, and failure analysis.  
This hands-on experimentation led to a deeper understanding of model behavior and performance tradeoffs.

---

## ðŸ§  Task 2: Diabetes Prediction (Binary Classification)

This task involved predicting whether an individual was diabetic based on medical and demographic features.  
The dataset had both missing values and imbalanced classes, making preprocessing and model choice crucial.

### ðŸ“„ Baseline Overview
The baseline model used a simple RandomForestClassifier without tuning or advanced preprocessing.

ðŸ“ [Baseline Notebook (to be added)](./ë‹¹ë‡¨ë³‘ ì˜ˆì¸¡ ì´ì§„ë¶„ë¥˜(ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œ).ipynb)

---

## ðŸ§ª Experiment Timeline Summary

Total of 40+ submissions, key phases:

### ðŸ”¹ Phase 1: Data Cleaning & Feature Addition (#1â€“#6)
- Handled missing values using domain logic (e.g., ìµœë¹ˆê°’, ì„±ë³„ â†’ ì—¬ì„±)
- Added derived features: ë‹¹í™”í˜ˆìƒ‰ì†Œ ê´€ë ¨ íŒŒìƒ ë³€ìˆ˜
- âœ… Best improvement from manually added features

### ðŸ”¹ Phase 2: Model Exploration (#7â€“#13)
- Tried LightGBM, CatBoost, RandomForest
- LightGBM yielded best scores with minimal tuning

### ðŸ”¹ Phase 3: Feature Engineering & Selection (#14â€“#20)
- Interaction variables (ex: [BMI Ã— í˜ˆë‹¹], [ë‚˜ì´ Ã— ë‹¹í™”í˜ˆìƒ‰ì†Œ])
- Best result at **Submission #18**, Kaggle: **0.811983**

### ðŸ”¹ Phase 4: Ensemble & Tuning (#21â€“#40)
- Applied:
  - Stacking, Voting
  - Class weights
  - SMOTE
  - Optuna-based tuning
- F1 Macro Score peaked at **0.894** on validation, Kaggle best: **0.811983**

---

## ðŸ¤– Models Used

| Model | ì‚¬ìš© ì—¬ë¶€ | ë¹„ê³  |
|-------|-----------|------|
| `LightGBM` | âœ… Best performer | íŠœë‹ ë° ì•™ìƒë¸”ì— ê°€ìž¥ ì í•© |
| `CatBoost` | âœ… ì•ˆì •ì  ì„±ëŠ¥ | ì¼ë¶€ ì‹¤í—˜ì—ì„œ ì‚¬ìš© |
| `XGBoost` | âœ… ìµœì¢… íŠœë‹ìš© | ì¼ë¶€ íŠ¹ì„± ì¡°í•©ì—ì„œ ì„±ëŠ¥ ìš°ìˆ˜ |
| `RandomForest` | âœ… ë² ì´ìŠ¤ë¼ì¸ | ì´ˆê¸° ì‹¤í—˜ìš© |
| `SVM` | âŒ Not effective | ì‹¤í—˜í–ˆìœ¼ë‚˜ ì„±ëŠ¥ ë‚®ìŒ |

---

## ðŸ§  Key Learnings

- Simple feature combinations like [ë‹¹í™”í˜ˆìƒ‰ì†Œ, í˜ˆë‹¹ì°¨ì´] produced strong signals
- Overengineering sometimes degraded performance
- LightGBM + Optuna + Feature Selection = ìµœì ì˜ ì¡°í•©
- Pseudo labeling ë° SMOTEëŠ” ì£¼ì˜ê°€ í•„ìš”í•¨

> ðŸ“Œ From feature engineering to ensemble strategy,  
> I learned the importance of balancing model complexity and generalizability.





