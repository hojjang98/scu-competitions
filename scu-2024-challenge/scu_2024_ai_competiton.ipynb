{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdad0366",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 1. Download and unzip data\n",
        "# ===========================\n",
        "!gdown 1IOgB_HQs0BrXsD4DssDnHAlsmtmWCEN7  # Download data file\n",
        "!unzip -oqq scu-ai-competition-202401.zip  # Unzip the dataset\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 2. Environment setup\n",
        "# ===========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from sklearn.preprocessing import (\n",
        "    OneHotEncoder,\n",
        "    MinMaxScaler,\n",
        "    StandardScaler,\n",
        "    RobustScaler,\n",
        "    PowerTransformer,\n",
        ")\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from lightgbm import LGBMClassifier, early_stopping\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "SEED = 42\n",
        "DATA_PATH = \"./\"\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 3. Load datasets\n",
        "# ===========================\n",
        "train = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
        "test = pd.read_csv(f\"{DATA_PATH}test.csv\")\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape:\", test.shape)\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 4. Handle missing values\n",
        "# ===========================\n",
        "# Fill numerical columns with mean\n",
        "fill_tsh = train[\"TSH\"].mean()\n",
        "fill_free_t3 = train[\"FreeT3\"].mean()\n",
        "fill_free_t4 = train[\"FreeT4\"].mean()\n",
        "\n",
        "# Common preprocessing for both train and test\n",
        "for df in [train, test]:\n",
        "    df[\"\ub098\uc774\"] = df[\"\ub098\uc774\"].fillna(0)\n",
        "    df[\"\uc131\ubcc4\"] = df[\"\uc131\ubcc4\"].fillna(\"UNK\")\n",
        "    df[\"TSH\"] = df[\"TSH\"].fillna(fill_tsh)\n",
        "    df[\"FreeT3\"] = df[\"FreeT3\"].fillna(fill_free_t3)\n",
        "    df[\"FreeT4\"] = df[\"FreeT4\"].fillna(fill_free_t4)\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 5. Convert binary categorical features\n",
        "# ===========================\n",
        "binary_cols = [col for col in train.columns if col.endswith(\"\uc5ec\ubd80\") or col.endswith(\"\uc774\ub825\")]\n",
        "for df in [train, test]:\n",
        "    df[binary_cols] = (df[binary_cols] == \"\uc608\").astype(int)\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 6. Feature engineering\n",
        "# ===========================\n",
        "# Remove ID and target column\n",
        "train_ft = train.iloc[:, 1:-1].copy()\n",
        "test_ft = test.iloc[:, 1:].copy()\n",
        "\n",
        "# Add a feature representing total 'yes' counts\n",
        "train_ft[\"yes_sum\"] = train_ft[binary_cols].sum(axis=1)\n",
        "test_ft[\"yes_sum\"] = test_ft[binary_cols].sum(axis=1)\n",
        "\n",
        "# Create interaction features using 2- and 3-way combinations\n",
        "for n in [2, 3]:\n",
        "    for comb in combinations(binary_cols, n):\n",
        "        name = \"_\".join(comb)\n",
        "        train_ft[name] = train_ft[list(comb)].sum(axis=1)\n",
        "        test_ft[name] = test_ft[list(comb)].sum(axis=1)\n",
        "\n",
        "# Add a ratio feature between FreeT4 and FreeT3\n",
        "train_ft[\"FreeT4_FreeT3\"] = train_ft[\"FreeT4\"] / train_ft[\"FreeT3\"]\n",
        "test_ft[\"FreeT4_FreeT3\"] = test_ft[\"FreeT4\"] / test_ft[\"FreeT3\"]\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 7. One-hot encoding\n",
        "# ===========================\n",
        "cat_cols = train_ft.select_dtypes(\"object\").columns.tolist()\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "\n",
        "train_ohe = pd.DataFrame(\n",
        "    ohe.fit_transform(train_ft[cat_cols]).toarray(),\n",
        "    columns=ohe.get_feature_names_out(cat_cols)\n",
        ")\n",
        "test_ohe = pd.DataFrame(\n",
        "    ohe.transform(test_ft[cat_cols]).toarray(),\n",
        "    columns=ohe.get_feature_names_out(cat_cols)\n",
        ")\n",
        "\n",
        "train_ft = pd.concat([train_ft.drop(columns=cat_cols), train_ohe], axis=1)\n",
        "test_ft = pd.concat([test_ft.drop(columns=cat_cols), test_ohe], axis=1)\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 8. Feature scaling\n",
        "# ===========================\n",
        "scaler = MinMaxScaler()\n",
        "train_ft[:] = scaler.fit_transform(train_ft)\n",
        "test_ft[:] = scaler.transform(test_ft)\n",
        "\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 9. Set target variable\n",
        "# ===========================\n",
        "target = train[\"target\"]\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 10. Feature selection using SelectPercentile\n",
        "# ===========================\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "cv_scores = []\n",
        "\n",
        "# Evaluate performance across percentiles (5% to 95%)\n",
        "for p in tqdm(range(5, 96)):\n",
        "    selector = SelectPercentile(percentile=p)\n",
        "    selector.fit(train_ft, target)\n",
        "    X_selected = selector.transform(train_ft)\n",
        "\n",
        "    model = LGBMClassifier(random_state=SEED)\n",
        "    scores = cross_val_score(model, X_selected, target, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
        "    cv_scores.append([p, scores.mean()])\n",
        "\n",
        "# Identify the best percentile\n",
        "cv_scores = np.array(cv_scores)\n",
        "best_idx = np.argmax(cv_scores[:, 1])\n",
        "best_percentile = cv_scores[best_idx, 0]\n",
        "\n",
        "# Plot performance\n",
        "plt.plot(cv_scores[:, 0], cv_scores[:, 1])\n",
        "plt.xlabel(\"Percentile\")\n",
        "plt.ylabel(\"CV F1 Score\")\n",
        "plt.grid(True)\n",
        "plt.title(\"Feature Selection Performance\")\n",
        "plt.show()\n",
        "\n",
        "# Select features using the best percentile\n",
        "selector = SelectPercentile(percentile=best_percentile)\n",
        "selector.fit(train_ft, target)\n",
        "best_features = selector.get_feature_names_out()\n",
        "\n",
        "train_ft = train_ft[best_features]\n",
        "test_ft = test_ft[best_features]\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 11. Train model using K-Fold Cross Validation\n",
        "# ===========================\n",
        "from lightgbm import LGBMClassifier, early_stopping\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model_list = []\n",
        "score_list = []\n",
        "\n",
        "for train_idx, valid_idx in cv.split(train_ft, target):\n",
        "    X_train, y_train = train_ft.iloc[train_idx], target.iloc[train_idx]\n",
        "    X_valid, y_valid = train_ft.iloc[valid_idx], target.iloc[valid_idx]\n",
        "\n",
        "    model = LGBMClassifier(\n",
        "        random_state=SEED,\n",
        "        n_estimators=1000,\n",
        "        verbosity=-1\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        callbacks=[early_stopping(300)]\n",
        "    )\n",
        "\n",
        "    pred = model.predict(X_valid)\n",
        "    score = f1_score(y_valid, pred)\n",
        "\n",
        "    score_list.append(score)\n",
        "    model_list.append(model)\n",
        "\n",
        "print(\"Validation F1 Scores per Fold:\", score_list)\n",
        "print(\"Average Validation F1 Score:\", np.mean(score_list))\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 12. Predict on test set with soft voting\n",
        "# ===========================\n",
        "pred_list = [model.predict_proba(test_ft)[:, 1] for model in model_list]\n",
        "pred = np.mean(pred_list, axis=0)\n",
        "pred_binary = (pred > 0.5).astype(int)\n",
        "\n",
        "# ===========================\n",
        "# \ud83d\udd3d 13. Create submission file\n",
        "# ===========================\n",
        "submit = pd.read_csv(f\"{DATA_PATH}sample_submission.csv\")\n",
        "submit[\"target\"] = pred_binary\n",
        "submit.to_csv(\"AI_Competiton_Submit.csv\", index=False)\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}